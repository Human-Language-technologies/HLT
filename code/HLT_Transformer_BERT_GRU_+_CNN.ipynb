{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "HLT Transformer - BERT - GRU + CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9a5fc513af546429b73ef8107416f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8cda25edf2304f02b8399cfa506cf712",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f4145609ced4643a62cbf05f7b97ef3",
              "IPY_MODEL_b169b249b4ac4305ab7a1c888fdd49db"
            ]
          }
        },
        "8cda25edf2304f02b8399cfa506cf712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f4145609ced4643a62cbf05f7b97ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e925aa7e4cdd45a4bc6b47ccd11d10a7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7bf6a1ca57944e5f92c2d7f3595ba2c7"
          }
        },
        "b169b249b4ac4305ab7a1c888fdd49db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d957c13be5cf4139bd21eff410527f6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.64MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6ef0005af55462faa4d0261a349b5ad"
          }
        },
        "e925aa7e4cdd45a4bc6b47ccd11d10a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7bf6a1ca57944e5f92c2d7f3595ba2c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d957c13be5cf4139bd21eff410527f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6ef0005af55462faa4d0261a349b5ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6ueDy4w2-PJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "7f0c4fb2-50f5-481f-81cf-21653e4306b7"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 38.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=92e48e25d7c5729b569bd4e25eeb7c610f87db6bcf8e1fe896ac2741f857e7b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDGQ0AoV2zl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import torch.nn as nn\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import time\n",
        "import random\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wVhm0fC2zmB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "e9a5fc513af546429b73ef8107416f71",
            "8cda25edf2304f02b8399cfa506cf712",
            "8f4145609ced4643a62cbf05f7b97ef3",
            "b169b249b4ac4305ab7a1c888fdd49db",
            "e925aa7e4cdd45a4bc6b47ccd11d10a7",
            "7bf6a1ca57944e5f92c2d7f3595ba2c7",
            "d957c13be5cf4139bd21eff410527f6b",
            "d6ef0005af55462faa4d0261a349b5ad"
          ]
        },
        "outputId": "1d9af8aa-678d-45fd-c238-8c554a60781a"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9a5fc513af546429b73ef8107416f71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22vss3mo2zmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "215e91b4-d199-4c90-ffc7-0771dd8ef3f4"
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9gz_BdV2zmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d120f358-1d1b-443b-c400-f8956e86be23"
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVnX5uiD2zmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "024a68fe-8c5c-46fa-a185-bbb997afa467"
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONlNBmRN2zmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_cut(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQdNYAF4ja9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f80d9ba-ddb5-4f43-9810-be6340c8fc25"
      },
      "source": [
        "tokenize_and_cut('positive and good')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['positive', 'and', 'good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWLTMNe-jkLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c846dbc-f1b4-4c04-ea14-3902a7e2d1d4"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids('positive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuUJn7kr2zmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "SELECTED_TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvKdDbWG2zmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields = [(None, None), ('text', TEXT), ('selected_text', SELECTED_TEXT), ('label', LABEL)]\n",
        "#add selected text!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUqJt3hi2zmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = data.TabularDataset.splits(\n",
        "                                        path = '',\n",
        "                                        train = 'train_full.csv',\n",
        "                                        format = 'csv',\n",
        "                                        fields = fields,\n",
        "                                        skip_header = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vtVIoVb65ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('train_full.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PZG2ejJ7Bqv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "52b62a27-e86a-498c-e07d-d72b00cfa422"
      },
      "source": [
        "df.sentiment.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     11118\n",
              "positive     8582\n",
              "negative     7781\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TH4ZZim2zmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = train_data[0].split(random_state = random.seed(SEED), split_ratio=0.8)\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED), split_ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VNXUBka2zmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "cf1db495-a9b4-4b1d-a560-13c7ce240678"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17588\n",
            "Number of validation examples: 4397\n",
            "Number of testing examples: 5496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORbBnfPg2zmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY2NdLC-Ly-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9189b1a3-33d1-4f74-b9b5-5fb0cd6bcdb3"
      },
      "source": [
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in LABEL vocabulary: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8_bS1Iz2zmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75b0e7f9-f979-439f-f8ed-2ee912d34093"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f56b148f510>, {'neutral': 0, 'positive': 1, 'negative': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD8f85f32zmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device, sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY3-JdAp2zmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuwyiAdl2zmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                 n_filters,\n",
        "                 filter_size):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size'] #768\n",
        "        \n",
        "        #adding cnn\n",
        "        self.conv = nn.Conv2d(in_channels = 1, \n",
        "                                out_channels = n_filters, \n",
        "                                kernel_size = (filter_size, embedding_dim)) #3, 768\n",
        "\n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        #self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim) #gru\n",
        "        #self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim) #cnn\n",
        "\n",
        "        # concatenate output\n",
        "        self.out = nn.Linear(n_filters + hidden_dim * 2 if bidirectional else hidden_dim, output_dim )\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0]\n",
        "\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "\n",
        "        embedded_cnn = embedded.unsqueeze(1) #create a new dimension\n",
        "        #print(embedded_cnn.shape)\n",
        "        conved = F.relu(self.conv(embedded_cnn)).squeeze(3)\n",
        "        #print (conved.shape)\n",
        "        pooled = F.max_pool1d(conved, conved.shape[2]).squeeze(2)\n",
        "        #print (pooled.shape)\n",
        "        #pooled_n = [batch size, n_filters]\n",
        "\n",
        "        # concatenate two outputs (cnn, gru)\n",
        "        cat = self.dropout(torch.cat((pooled, hidden), dim = 1))\n",
        "\n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(cat)   \n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euR1YQRb2zmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 2\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZE = 3\n",
        "\n",
        "model = BERTGRUSentiment(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT,\n",
        "                         N_FILTERS,\n",
        "                         FILTER_SIZE\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9uzgcZo2zm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9dfc4aff-a61c-4553-9f49-49309205acbf"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 112,472,622 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9kQ5-OX2zm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9-RUk8X2zm4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d966c4e-b2da-47e9-9bfd-3c6a4708813b"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,990,382 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICUv-MYq2zm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "277aa8ec-95fd-44bc-84dc-3f800dcd2563"
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv.weight\n",
            "conv.bias\n",
            "rnn.weight_ih_l0\n",
            "rnn.weight_hh_l0\n",
            "rnn.bias_ih_l0\n",
            "rnn.bias_hh_l0\n",
            "rnn.weight_ih_l0_reverse\n",
            "rnn.weight_hh_l0_reverse\n",
            "rnn.bias_ih_l0_reverse\n",
            "rnn.bias_hh_l0_reverse\n",
            "rnn.weight_ih_l1\n",
            "rnn.weight_hh_l1\n",
            "rnn.bias_ih_l1\n",
            "rnn.bias_hh_l1\n",
            "rnn.weight_ih_l1_reverse\n",
            "rnn.weight_hh_l1_reverse\n",
            "rnn.bias_ih_l1_reverse\n",
            "rnn.bias_hh_l1_reverse\n",
            "out.weight\n",
            "out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5CNOOPE2zm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jldQ7TPS2znA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criterion = nn.CrossEntropyLoss()\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95b_Czu82znC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UnHXHZX2znE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    # preds is output (3 values)\n",
        "    # y is other vector of right labels\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y) # return a vector, 1 if the two cells are equal\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHu-8s6xhB9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def intersection(lst1, lst2): \n",
        "    #return [value for value in lst1 if value in lst2] \n",
        "    return list((Counter(lst1.tolist()) & Counter(lst2.tolist())).elements()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccCyjyRPhQTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jaccard_similarity(list1,list2):\n",
        "    lenIntersection=len(intersection(list1,list2))\n",
        "    union=(len(list1)+len(list2)) - lenIntersection\n",
        "    if union == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(lenIntersection)/union"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngcsRDBqaqhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating jaccard for pytorch tensors\n",
        "def jaccard(text, pred, y):\n",
        "    jaccard = 0\n",
        "    for i, v in enumerate(text):\n",
        "        jacc_value = jaccard_similarity(v[pred[i][0].round().int().item():pred[i][1].round().int().item()],\n",
        "                                      v[y[i][0].round().int().item():y[i][1].round().int().item()])\n",
        "        jaccard += jacc_value\n",
        "    result = jaccard / torch.FloatTensor([text.shape[0]])\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7cnmVdVL8iA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting labels into bert ids\n",
        "def LabelToId(x):\n",
        "    return tokenizer.convert_tokens_to_ids(LABEL.vocab.itos[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7VVgPb1JutS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#init token + label id + pad token + pad token + text ids\n",
        "def process(text, label):\n",
        "    result = torch.tensor(np.full((label.shape[0],1), init_token_idx), dtype=torch.int64, device=device)\n",
        "    pad = torch.tensor(np.full((label.shape[0],1), pad_token_idx), dtype=torch.int64, device=device)\n",
        "    labels_idx = torch.empty((label.shape), dtype=torch.int64, device=device)\n",
        "    for i, v in enumerate(label):\n",
        "        labels_idx[i] = LabelToId(int(v.item()))\n",
        "    labels_idx = labels_idx.unsqueeze(1)\n",
        "    result = torch.cat((result, labels_idx), 1)\n",
        "    result = torch.cat((result, pad) , 1)\n",
        "    result = torch.cat((result, pad) , 1)\n",
        "\n",
        "    result = torch.cat((result, text[:, 1:]), 1)\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIlpO34lKLBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting begin position and end position of selected text in original text\n",
        "def get_positions(text, selected_text):\n",
        "    selected_text_ = selected_text[:, 1:]\n",
        "    text_ = text[:, 1:]\n",
        "    result = torch.empty((1,2), dtype=torch.int64)\n",
        "    for i, v in enumerate(text_):\n",
        "        start_position = 0\n",
        "        end_position = 0\n",
        "        for j in range(v.shape[0]):\n",
        "            if selected_text_[i][0].item() == v[j].item():\n",
        "                for k in range(selected_text_[i].shape[0]):\n",
        "                    if selected_text_[i][k].item() == v[j+k].item():\n",
        "                        if k==0:\n",
        "                            start_position = j\n",
        "                        if selected_text_[i][k].item() == eos_token_idx:\n",
        "                            end_position = j+k\n",
        "                            break\n",
        "                    else:\n",
        "                        end_position = j+k\n",
        "                        break\n",
        "        start_position += 4\n",
        "        end_position += 4\n",
        "        positions = torch.tensor([[start_position, end_position]], dtype=torch.int64)\n",
        "        result = torch.cat((result, positions), 0)\n",
        "    return result[1:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEAK06DkFn_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating random positions as baseline\n",
        "def create_baseline(text, pos):\n",
        "    result = torch.empty((pos.shape))\n",
        "    for i, v in enumerate(text):\n",
        "        first = random.randint(4, (v==eos_token_idx).nonzero().item())\n",
        "        second = random.randint(first, (v==eos_token_idx).nonzero().item())\n",
        "        result[i] = torch.tensor([[first, second]])\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFGR2SdS2znG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_jacc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        input = process(batch.text, batch.label)\n",
        "\n",
        "        positions = get_positions(batch.text, batch.selected_text).float().to(device)\n",
        "\n",
        "        predictions = model(input)\n",
        "        \n",
        "        loss = criterion(predictions, positions)\n",
        "        \n",
        "        jacc = jaccard(input, predictions, positions)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_jacc += jacc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_jacc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9BDtlhU2znI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_jacc = 0\n",
        "    epoch_jacc_baseline = 0\n",
        "    epoch_loss_baseline = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            input = process(batch.text, batch.label)\n",
        "            positions = get_positions(batch.text, batch.selected_text).float().to(device)\n",
        "\n",
        "            predictions = model(input)\n",
        "            \n",
        "            loss = criterion(predictions, positions)\n",
        "            \n",
        "            jacc = jaccard(input, predictions, positions)\n",
        "\n",
        "            baseline = create_baseline(input, positions).to(device)\n",
        "            jacc_baseline = jaccard(input, baseline, positions)\n",
        "            loss_baseline = criterion(baseline, positions)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_jacc += jacc.item()\n",
        "            epoch_jacc_baseline += jacc_baseline.item()\n",
        "            epoch_loss_baseline += loss_baseline.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_jacc / len(iterator), epoch_loss_baseline / len(iterator), epoch_jacc_baseline / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrRFRa6X2znM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CnjkmHzIBNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss_plot = []\n",
        "train_jacc_plot = []\n",
        "valid_loss_plot = []\n",
        "valid_jacc_plot = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Sp4yur2znO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b780664-e200-41bd-dc21-59b3048665aa"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_jacc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_jacc, baseline_loss, baseline_jacc = evaluate(model, valid_iterator, criterion)\n",
        "    train_loss_plot.append(train_loss)\n",
        "    train_jacc_plot.append(train_jacc)\n",
        "    valid_loss_plot.append(valid_loss)\n",
        "    valid_jacc_plot.append(valid_jacc)\n",
        "        \n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bert-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Jacc: {train_jacc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Jacc: {valid_jacc*100:.2f}%')\n",
        "    print(f'\\t  BL. Loss: {baseline_loss:.3f} |   BL. Jacc: {baseline_jacc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 3m 52s\n",
            "\tTrain Loss: 53.486 | Train Jacc: 31.33%\n",
            "\t Val. Loss: 40.683 |  Val. Jacc: 36.74%\n",
            "\t  BL. Loss: 91.472 |   BL. Jacc: 16.10%\n",
            "Epoch: 02 | Epoch Time: 3m 51s\n",
            "\tTrain Loss: 40.771 | Train Jacc: 35.52%\n",
            "\t Val. Loss: 35.477 |  Val. Jacc: 36.77%\n",
            "\t  BL. Loss: 90.655 |   BL. Jacc: 16.62%\n",
            "Epoch: 03 | Epoch Time: 3m 51s\n",
            "\tTrain Loss: 36.986 | Train Jacc: 37.05%\n",
            "\t Val. Loss: 31.687 |  Val. Jacc: 42.38%\n",
            "\t  BL. Loss: 91.529 |   BL. Jacc: 16.26%\n",
            "Epoch: 04 | Epoch Time: 3m 51s\n",
            "\tTrain Loss: 34.215 | Train Jacc: 37.74%\n",
            "\t Val. Loss: 32.644 |  Val. Jacc: 41.60%\n",
            "\t  BL. Loss: 88.748 |   BL. Jacc: 15.97%\n",
            "Epoch: 05 | Epoch Time: 3m 49s\n",
            "\tTrain Loss: 32.410 | Train Jacc: 38.26%\n",
            "\t Val. Loss: 30.652 |  Val. Jacc: 42.31%\n",
            "\t  BL. Loss: 94.030 |   BL. Jacc: 15.71%\n",
            "Epoch: 06 | Epoch Time: 3m 45s\n",
            "\tTrain Loss: 30.480 | Train Jacc: 38.94%\n",
            "\t Val. Loss: 30.972 |  Val. Jacc: 44.09%\n",
            "\t  BL. Loss: 90.930 |   BL. Jacc: 16.14%\n",
            "Epoch: 07 | Epoch Time: 3m 46s\n",
            "\tTrain Loss: 28.842 | Train Jacc: 39.47%\n",
            "\t Val. Loss: 32.412 |  Val. Jacc: 38.04%\n",
            "\t  BL. Loss: 92.765 |   BL. Jacc: 16.20%\n",
            "Epoch: 08 | Epoch Time: 3m 47s\n",
            "\tTrain Loss: 27.497 | Train Jacc: 39.76%\n",
            "\t Val. Loss: 32.461 |  Val. Jacc: 40.26%\n",
            "\t  BL. Loss: 91.518 |   BL. Jacc: 16.00%\n",
            "Epoch: 09 | Epoch Time: 3m 45s\n",
            "\tTrain Loss: 26.188 | Train Jacc: 40.42%\n",
            "\t Val. Loss: 31.329 |  Val. Jacc: 44.19%\n",
            "\t  BL. Loss: 90.690 |   BL. Jacc: 16.73%\n",
            "Epoch: 10 | Epoch Time: 3m 43s\n",
            "\tTrain Loss: 24.793 | Train Jacc: 40.54%\n",
            "\t Val. Loss: 30.818 |  Val. Jacc: 42.90%\n",
            "\t  BL. Loss: 89.089 |   BL. Jacc: 16.38%\n",
            "Epoch: 11 | Epoch Time: 3m 46s\n",
            "\tTrain Loss: 23.480 | Train Jacc: 40.86%\n",
            "\t Val. Loss: 30.558 |  Val. Jacc: 42.87%\n",
            "\t  BL. Loss: 94.325 |   BL. Jacc: 15.81%\n",
            "Epoch: 12 | Epoch Time: 3m 46s\n",
            "\tTrain Loss: 22.561 | Train Jacc: 41.32%\n",
            "\t Val. Loss: 32.665 |  Val. Jacc: 42.00%\n",
            "\t  BL. Loss: 91.991 |   BL. Jacc: 15.90%\n",
            "Epoch: 13 | Epoch Time: 3m 47s\n",
            "\tTrain Loss: 22.193 | Train Jacc: 41.19%\n",
            "\t Val. Loss: 33.048 |  Val. Jacc: 43.14%\n",
            "\t  BL. Loss: 90.658 |   BL. Jacc: 16.03%\n",
            "Epoch: 14 | Epoch Time: 3m 46s\n",
            "\tTrain Loss: 21.087 | Train Jacc: 41.86%\n",
            "\t Val. Loss: 31.497 |  Val. Jacc: 42.94%\n",
            "\t  BL. Loss: 93.862 |   BL. Jacc: 16.29%\n",
            "Epoch: 15 | Epoch Time: 3m 48s\n",
            "\tTrain Loss: 19.981 | Train Jacc: 41.82%\n",
            "\t Val. Loss: 31.968 |  Val. Jacc: 44.00%\n",
            "\t  BL. Loss: 89.674 |   BL. Jacc: 15.95%\n",
            "Epoch: 16 | Epoch Time: 3m 48s\n",
            "\tTrain Loss: 19.595 | Train Jacc: 42.15%\n",
            "\t Val. Loss: 31.058 |  Val. Jacc: 42.02%\n",
            "\t  BL. Loss: 88.455 |   BL. Jacc: 16.51%\n",
            "Epoch: 17 | Epoch Time: 3m 46s\n",
            "\tTrain Loss: 18.831 | Train Jacc: 42.35%\n",
            "\t Val. Loss: 32.468 |  Val. Jacc: 44.70%\n",
            "\t  BL. Loss: 89.429 |   BL. Jacc: 16.13%\n",
            "Epoch: 18 | Epoch Time: 3m 43s\n",
            "\tTrain Loss: 18.347 | Train Jacc: 42.30%\n",
            "\t Val. Loss: 34.185 |  Val. Jacc: 44.99%\n",
            "\t  BL. Loss: 90.288 |   BL. Jacc: 16.31%\n",
            "Epoch: 19 | Epoch Time: 3m 43s\n",
            "\tTrain Loss: 18.015 | Train Jacc: 42.44%\n",
            "\t Val. Loss: 34.596 |  Val. Jacc: 41.48%\n",
            "\t  BL. Loss: 89.789 |   BL. Jacc: 16.48%\n",
            "Epoch: 20 | Epoch Time: 3m 44s\n",
            "\tTrain Loss: 17.379 | Train Jacc: 42.68%\n",
            "\t Val. Loss: 31.254 |  Val. Jacc: 45.38%\n",
            "\t  BL. Loss: 89.922 |   BL. Jacc: 16.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFe533vWqwqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0b502fc-5f9d-4e49-9ae6-075901c97012"
      },
      "source": [
        "model.load_state_dict(torch.load('bert-model.pt'))\n",
        "\n",
        "test_loss, test_acc, _ , _ = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Jacc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 32.881 | Test Jacc: 43.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM2tUiyK2znQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_sentiment(model, tokenizer, sentence, label):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [init_token_idx] + [tokenizer.convert_tokens_to_ids(label)] +  [pad_token_idx] + [pad_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = model(tensor)\n",
        "    #max_preds = prediction.argmax(dim = 1)\n",
        "    return prediction, indexed\n",
        "    #return max_preds.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs0dPeKIVWdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "868cf420-23cf-4ecc-e700-7712c552a6ce"
      },
      "source": [
        "sentence = \"I am very sorry. Today is very ugly.\"\n",
        "label = \"negative\"\n",
        "pred_class, indexed = predict_sentiment(model, tokenizer, sentence , label)\n",
        "result = [tokenizer.convert_ids_to_tokens(i) for i in indexed[pred_class[0][0].round().int().item():pred_class[0][1].round().int().item()]]\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sorry', '.', 'today']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}